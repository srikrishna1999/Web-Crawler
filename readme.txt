Files Present:

1. crawler.py - python script to initiate the crawler.
2. seeds1.txt - contains twenty random seeds from the whole seeds list given.
3. seeds2.txt - contains twenty more random seeds from the whole seeds list given.
4. Web Crawler Log 1.txt - contains the log of the url crawled with details 
    such as url, time, page_size, depth, page_status for the seeds from seeds1.txt file.
5. Web Crawler Log 2.txt - contains the log of the url crawled with details 
    such as url, time, page_size, depth, page_status for the seeds from seeds2.txt file.

Packages Required:
1. beautifulsoup4==4.12.3

Steps to Run the Program:

1. Activate the py3-env environmental variable.
2. Run "python3 crawler.py".